# -*- coding: utf-8 -*-
"""Email Subject Categorization

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ml09nakWphAIuLEyUN-HzmdE5u1Pc-Eg

# **Email Subject Categorization**
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

df = pd.read_csv('/content/Email_Subject_Classifier.csv.zip')
df.head()

df.shape

df['category'].unique()

df['category'].value_counts()

df.drop('priority', axis=1, inplace=True)

df.head()

df.rename(columns={'mail':'Subject'}, inplace=True)

df.head()

df.isnull().sum()

a = df['category'].unique()
plt.pie(df["category"].value_counts(),labels=a,autopct="%.2f%%")
plt.show()

"""# **Text Preprocessing**"""

import nltk
# Download the 'punkt_tab' data package
nltk.download('punkt_tab')
import string
import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords

from nltk.stem import WordNetLemmatizer

nltk.download('wordnet')
nltk.download('omw-1.4')

lemmatizer = WordNetLemmatizer()

lemmatizer = WordNetLemmatizer()

# Lower case
# Tokenize
# Removing Special characters
# Removing stop words and punctuation
# Lemmatization

def transform(text):
    text=text.lower()
    text=nltk.word_tokenize(text)

    y=[]
    for i in text:
         if i.isalnum(): #isalnum mean alphanumeric or numeric
            y.append(i)

    text=y[:]
    y.clear()
    for i in text:
        if i not in string.punctuation and i not in stopwords.words('english'):
            y.append(i)

    text = y[:]
    y.clear()
    for i in text:
        y.append(lemmatizer.lemmatize(i))

    return " ".join(y)

df["Transformed_Text"]=df["Subject"].apply(transform)

df.head()

"""# **Label Encoding and TFIDF**"""

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['category_encoded'] = le.fit_transform(df['category'])

df['category_encoded'].unique()

df['category'].unique()

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer()
x = tfidf.fit_transform(df["Transformed_Text"]).toarray()

y=df["category_encoded"].values
y

"""# **Test Train Split**"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

"""# **Model Building**"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score

model = MultinomialNB()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))

# Function to predict category from new email text
def predict_category(text_input):
    # Convert input text to TF-IDF vector
    text_vector = tfidf.transform([text_input])  # input must be a list
    prediction = model.predict(text_vector)      # get predicted label (numeric)
    category = le.inverse_transform(prediction)  # decode back to category name
    return category[0]

predict_category(df["Subject"][0])

df["Subject"][0]

predict_category(df["Subject"][1])

df["Subject"][1]

predict_category(df["Subject"][2])

df["Subject"][2]

"""# **Streamlit App**"""

import joblib

# Save LabelEncoder
joblib.dump(le, '/content/label_encoder.joblib')
print("✅ LabelEncoder saved successfully!")


# Save the TF-IDF vectorizer
tfidf_path = "/content/tfidf.joblib"
joblib.dump(tfidf, tfidf_path)
print("✅ TF-IDF Vectorizer saved successfully!")


joblib.dump(model, '/content/Email_Subject_NLP.joblib')

!pip install streamlit
!pip install pyngrok

!streamlit run /content/app.py &> /content/logs.txt &

!npx localtunnel --port 8501